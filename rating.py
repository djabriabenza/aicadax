# -*- coding: utf-8 -*-
"""
Created on Thu Apr 10 03:22:58 2025

@author: djabr
"""


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

df = pd.read_csv("D:\Datasets/etud.csv")

import pandas as pd

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
df = pd.read_csv("D:\\Datasets\\etud.csv")  # Ù„Ø§Ø­Ø¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… \\ Ø£Ùˆ r"..." Ù„ØªÙØ§Ø¯ÙŠ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…Ø³Ø§Ø±

# Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 ØµÙÙˆÙ
print("Ø£ÙˆÙ„ 5 ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
print(df.head())

# Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø© Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
print("\nÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø© Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
print(df.info())

# Ø¹Ø±Ø¶ Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø§Ø¨ ÙÙŠ ÙƒÙ„ Ù…Ø§Ø¯Ø© (Course)
print("\nØ¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø§Ø¨ ÙÙŠ ÙƒÙ„ Ù…Ø§Ø¯Ø©:")
print(df['Course'].value_counts())

# Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ±ÙŠØ¯Ø©
print("\nÙ‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ±ÙŠØ¯Ø©:")
print(df['Course'].unique())


import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
df = pd.read_csv("D:\\Datasets\\etud.csv")

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… ÙƒØ§Ù…Ù„ Ù„ØªØ­Ø¯ÙŠØ¯ ÙƒÙ„ Ø·Ø§Ù„Ø¨
df['FullName'] = df['Firstname'] + ' ' + df['Lastname']

# pivot table: Ø§Ù„ØµÙÙˆÙ = Ø§Ù„Ø·Ù„Ø§Ø¨ØŒ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© = Ø§Ù„Ù…ÙˆØ§Ø¯ØŒ Ø§Ù„Ù‚ÙŠÙ… = 1 Ø¥Ø°Ø§ Ù…Ø³Ø¬Ù„
pivot_df = pd.crosstab(df['FullName'], df['Course'])

# Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø·Ù„Ø§Ø¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… cosine similarity
similarity_matrix = cosine_similarity(pivot_df)

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ØµÙÙˆÙØ© Ø¥Ù„Ù‰ DataFrame Ù„Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„ØªØ¹Ø§Ù…Ù„
similarity_df = pd.DataFrame(similarity_matrix, index=pivot_df.index, columns=pivot_df.index)

# Ø§Ø®ØªÙŠØ§Ø± Ø·Ø§Ù„Ø¨ Ù…Ø¹ÙŠÙ† (Ù…Ø«Ø§Ù„)
target_student = pivot_df.index[0]  # Ù…Ù…ÙƒÙ† ØªØºÙŠÙŠØ±Ù‡ Ù„Ø£ÙŠ Ø§Ø³Ù… Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙƒØ«Ø± Ø§Ù„Ø·Ù„Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡Ù‹Ø§
most_similar_students = similarity_df[target_student].sort_values(ascending=False)[1:6]  # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù†ÙØ³Ù‡

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªÙŠ Ø£Ø®Ø°Ù‡Ø§ Ø§Ù„Ø·Ø§Ù„Ø¨
student_courses = set(df[df['FullName'] == target_student]['Course'])

# ØªÙˆØµÙŠØ§Øª: Ø¯ÙˆØ±Ø§Øª Ø£Ø®Ø°Ù‡Ø§ Ø§Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡ÙˆÙ† ÙˆÙ„Ù… ÙŠØ£Ø®Ø°Ù‡Ø§ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„Ø­Ø§Ù„ÙŠ
recommended_courses = set()
for similar_student in most_similar_students.index:
    courses = set(df[df['FullName'] == similar_student]['Course'])
    recommended_courses.update(courses - student_courses)

print(f"Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù„Ù„Ø·Ø§Ù„Ø¨ {target_student}:")
print(recommended_courses)

import numpy as np

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³ØªÙˆÙ‰ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø¹Ø´ÙˆØ§Ø¦ÙŠ
levels = ['Ø³Ù†Ø© Ø£ÙˆÙ„Ù‰', 'Ø³Ù†Ø© Ø«Ø§Ù†ÙŠØ©', 'Ù…Ø§Ø¬Ø³ØªÙŠØ±']
df['Level'] = np.random.choice(levels, size=len(df))

# Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© (Ø¨ÙŠÙ† 10 Ùˆ 20)
df['Grade'] = np.round(np.random.uniform(10, 20, size=len(df)), 2)

# ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø§Ø¯Ø© Ù…Ù† Ø·Ø±Ù Ø§Ù„Ø·Ø§Ù„Ø¨ (1 Ø¥Ù„Ù‰ 5 Ù†Ø¬ÙˆÙ…)
df['Rating'] = np.random.randint(1, 6, size=len(df))

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
print(df.head())


from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity

# pivot: ÙƒÙ„ Ø·Ø§Ù„Ø¨ = ØµÙØŒ ÙˆÙƒÙ„ Ø¯ÙˆØ±Ø© = Ø¹Ù…ÙˆØ¯ (ØªØ£Ø®Ø° Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¹Ù„Ø§Ù…Ø©)
pivot_grades = df.pivot_table(index='FullName', columns='Course', values='Grade', fill_value=0)

# pivot: Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª
pivot_ratings = df.pivot_table(index='FullName', columns='Course', values='Rating', fill_value=0)

# Ø¯Ù…Ø¬ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª + Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª
combined_features = pd.concat([pivot_grades, pivot_ratings], axis=1)

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…
level_mapping = {'Ø³Ù†Ø© Ø£ÙˆÙ„Ù‰': 1, 'Ø³Ù†Ø© Ø«Ø§Ù†ÙŠØ©': 2, 'Ù…Ø§Ø¬Ø³ØªÙŠØ±': 3}
student_levels = df[['FullName', 'Level']].drop_duplicates().set_index('FullName')
student_levels['Level_Num'] = student_levels['Level'].map(level_mapping)

# Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø³ØªÙˆÙ‰
combined_features = combined_features.merge(student_levels['Level_Num'], left_index=True, right_index=True)

# ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ… (Normalization)
scaler = StandardScaler()
features_scaled = scaler.fit_transform(combined_features)

# Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
similarity_matrix = cosine_similarity(features_scaled)
similarity_df = pd.DataFrame(similarity_matrix, index=combined_features.index, columns=combined_features.index)

# ØªÙˆØµÙŠØ© Ù„Ø¯Ø±Ø§Ø³Ø© Ø·Ø§Ù„Ø¨ Ù…Ø¹ÙŠÙ†
target_student = combined_features.index[0]

# Ø§Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ø£ÙƒØ«Ø± ØªØ´Ø§Ø¨Ù‡Ù‹Ø§
similar_students = similarity_df[target_student].sort_values(ascending=False)[1:6]

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªÙŠ Ù„Ù… ÙŠØ£Ø®Ø°Ù‡Ø§ Ø§Ù„Ø·Ø§Ù„Ø¨
student_courses = set(df[df['FullName'] == target_student]['Course'])
recommended_courses = set()

for sim_student in similar_students.index:
    courses = set(df[df['FullName'] == sim_student]['Course'])
    recommended_courses.update(courses - student_courses)

print(f"ğŸ”® Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù„Ù„Ø·Ø§Ù„Ø¨ {target_student}:")
for course in recommended_courses:
    print("âœ…", course)